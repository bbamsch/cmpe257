{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from music21 import converter, instrument, note, chord\n",
    "\n",
    "#############################\n",
    "# MIDI Processing Utilities #\n",
    "#############################\n",
    "\n",
    "def ingest_midi(filename):\n",
    "    print(\"Ingesting... %s\" % filename)\n",
    "    midi = converter.parse(filename)\n",
    "    \n",
    "    # If there are multiple instrument tracks, focus\n",
    "    # only on the primary instrument in the MIDI.\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts and len(parts) > 0:\n",
    "        midi_events = parts.parts[0].recurse()\n",
    "    else:\n",
    "        midi_events = midi.flat.notes\n",
    "    \n",
    "    # Parse MIDI events for Notes and Chords\n",
    "    parsed_notes = []\n",
    "    for midi_event in midi_events:\n",
    "        if isinstance(midi_event, note.Note):\n",
    "            # For Note, add pitch to sequence\n",
    "            parsed_notes.append(midi_event.pitch.name)\n",
    "        elif isinstance(midi_event, chord.Chord):\n",
    "            # For Chord, join multiple pitches to sequence\n",
    "            parsed_notes.append(' '.join(pitch.name for pitch in midi_event.pitches))\n",
    "            \n",
    "    return parsed_notes, sorted(set(parsed_notes))\n",
    "\n",
    "\n",
    "def ingest_midis(file_glob):\n",
    "    notes_by_file = {}\n",
    "    vocab = set()\n",
    "    \n",
    "    for filename in glob.glob(file_glob):\n",
    "        file_notes, file_vocab = ingest_midi(filename)\n",
    "        \n",
    "        notes_by_file[filename] = file_notes\n",
    "        vocab.update(file_vocab)\n",
    "        \n",
    "    return notes_by_file, vocab\n",
    "\n",
    "\n",
    "def mkdir(filename):\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "\n",
    "\n",
    "def save_to_file(content, filename):\n",
    "    mkdir(filename)\n",
    "    pickle.dump(content, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def load_from_file(filename):\n",
    "    return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Transformation Utilities #\n",
    "############################\n",
    "\n",
    "def generate_note_to_int(vocab):\n",
    "    return dict((note, number) for number, note in enumerate(vocab))\n",
    "\n",
    "\n",
    "def generate_int_to_note(vocab):\n",
    "    return dict((number, note) for number, note in enumerate(vocab))\n",
    "\n",
    "\n",
    "def generate_sequences(notes_by_file, note_to_int, sequence_length = 100):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for notes in notes_by_file.values():\n",
    "        for i in range(0, len(notes) - sequence_length, 1):\n",
    "            # Sequence of N Input Notes --> 1 Output Note\n",
    "            input_sequence = notes[i:i + sequence_length]\n",
    "            output_sequence = notes[i + sequence_length]\n",
    "\n",
    "            x.append([note_to_int[c] for c in input_sequence])\n",
    "            y.append(note_to_int[output_sequence])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bbamsch/.virtualenvs/cmpe257/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "###################\n",
    "# Model Utilities #\n",
    "###################\n",
    "\n",
    "def build_model(input_width, output_width, model_file = None):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(256, input_shape=(input_width, 1), return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(output_width))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    if model_file:\n",
    "        model.load_weights(model_file)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, x, y, model_file, epochs=200, batch_size=128):\n",
    "    checkpoint = ModelCheckpoint(model_file, monitor='loss', save_best_only=True)\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(x, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21669 samples, validate on 9287 samples\n",
      "Epoch 1/1\n",
      "21669/21669 [==============================] - 364s 17ms/step - loss: 4.1705 - val_loss: 4.0158\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Process MIDI Files #\n",
    "######################\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import numpy\n",
    "\n",
    "def main():\n",
    "    # Load Cached Notes (if exists) or ingest all MIDI files\n",
    "    note_cache_file = 'model/cached-notes.pkl'\n",
    "    if os.path.exists(note_cache_file):\n",
    "        notes_by_file, vocab = load_from_file(note_cache_file)\n",
    "    else:\n",
    "        notes_by_file, vocab = ingest_midis(\"data/*.mid\")\n",
    "        save_to_file((notes_by_file, vocab), note_cache_file)\n",
    "\n",
    "    # Generate Sequences of 100 input Notes -> 1 output Note\n",
    "    sequence_length = 100\n",
    "    note_to_int = generate_note_to_int(vocab)\n",
    "    x, y = generate_sequences(\n",
    "        notes_by_file=notes_by_file,\n",
    "        note_to_int=note_to_int,\n",
    "        sequence_length=sequence_length)\n",
    "    \n",
    "    num_sequences = len(x)\n",
    "    num_vocab = len(vocab)\n",
    "    \n",
    "    # Reshape & Normalize Input Notes\n",
    "    x = numpy.reshape(x, (num_sequences, sequence_length, 1)) / num_vocab\n",
    "    # Transform Output to One Hot Encoding\n",
    "    y = np_utils.to_categorical(y)\n",
    "\n",
    "    # Build ML Model\n",
    "    model = build_model(sequence_length, num_vocab)\n",
    "\n",
    "    # Run Training w/ Checkpoints\n",
    "    train_model(\n",
    "        model=model,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        model_file=\"model/weights-improvements-{epoch:03d}-{loss:.4f}.hdf5\"\n",
    "    )\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
